backend: llama-cpp
context_size: 8192
f16: false
name: ""
parameters:
  model: galatolo-Q4_K.gguf
roles:
  assistant: '[|Assistente|] '
  system: '[|Umano|] '
  user: '[|Umano|] '
stopwords:
- '[|Umano|]'
template:
  chat: "Questa Ã¨ una conversazione tra un umano ed un assistente AI.\n{{.Input}}\n[|Assistente|]
    \ "
  completion: '{{.Input}}'
trimsuffix:
- |2+

